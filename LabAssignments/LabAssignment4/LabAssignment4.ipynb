{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Four: Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "- Juliana Antonio\n",
    "- Xiaona Hang\n",
    "- Chuanqi Deng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "data = pd.read_csv('data/acs2017_census_tract_data.csv')\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.select_dtypes(include='object').columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "if 'county' in data.columns:\n",
    "    data.drop(columns=['county'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove the 'county' column, to simplify the model to make it more interpretable. It also will reduce the overfitting risk that occurs with adding too many categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4  # Define the number of bins for quantization\n",
    "est = KBinsDiscretizer(n_bins=n_classes, encode='ordinal', strategy='uniform', subsample=None)\n",
    "data['ChildPoverty'] = est.fit_transform(data[['ChildPoverty']])\n",
    "\n",
    "X = data.drop(columns=['ChildPoverty'])\n",
    "y = data['ChildPoverty']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantization method was chosen for balancing the dataset because it offers a straightforward approach to dividing the continuous \"ChildPoverty\" variable into four equal intervals, ensuring approximately equal representation of each class. This method avoids the need for complex sampling techniques and maintains the integrity of the original data distribution while achieving balance for classification tasks. Balancing the dataset for both the training and testing sets ensures that each class is represented proportionally, preventing bias in model training and providing a fair evaluation of the model's performance across all classes. This improves the model's ability to generalize well and accurately assess its performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load, Split, and Balance \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://www.kaggle.com/muonneutrino/us-census-demographic-data/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
