{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Three: Extending Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "- Juliana Antonio\n",
    "- Xiaona Hang\n",
    "- Chuanqi Deng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13393, 8) (10714, 8) (2679, 8) (10714,) (2679,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from numpy.linalg import pinv\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "raw_data = pd.read_csv(\"data/bodyPerformance.csv\")\n",
    "\n",
    "# preprocessing\n",
    "data = pd.get_dummies(raw_data, columns=['gender'],dtype=np.int8) # one-hot encoding for gender\n",
    "labels = data['class'].map(lambda c: ord(c) - ord('A')) # encode lables into integer\n",
    "data.drop(['class'], axis=1, inplace=True) # remove class column\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(data)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(8)\n",
    "pca_feature = pca.fit_transform(features)\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_feature, labels, train_size=0.8)\n",
    "print(pca_feature.shape, X_train.shape, X_test.shape,  y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>body fat_%</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>systolic</th>\n",
       "      <th>gripForce</th>\n",
       "      <th>sit and bend forward_cm</th>\n",
       "      <th>sit-ups counts</th>\n",
       "      <th>broad jump_cm</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "      <td>13393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.775106</td>\n",
       "      <td>168.559807</td>\n",
       "      <td>67.447316</td>\n",
       "      <td>23.240165</td>\n",
       "      <td>78.796842</td>\n",
       "      <td>130.234817</td>\n",
       "      <td>36.963877</td>\n",
       "      <td>15.209268</td>\n",
       "      <td>39.771224</td>\n",
       "      <td>190.129627</td>\n",
       "      <td>0.367804</td>\n",
       "      <td>0.632196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.625639</td>\n",
       "      <td>8.426583</td>\n",
       "      <td>11.949666</td>\n",
       "      <td>7.256844</td>\n",
       "      <td>10.742033</td>\n",
       "      <td>14.713954</td>\n",
       "      <td>10.624864</td>\n",
       "      <td>8.456677</td>\n",
       "      <td>14.276698</td>\n",
       "      <td>39.868000</td>\n",
       "      <td>0.482226</td>\n",
       "      <td>0.482226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>162.400000</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>169.200000</td>\n",
       "      <td>67.400000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>37.900000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>174.800000</td>\n",
       "      <td>75.300000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>20.700000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>193.800000</td>\n",
       "      <td>138.100000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>156.200000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     height_cm     weight_kg    body fat_%     diastolic  \\\n",
       "count  13393.000000  13393.000000  13393.000000  13393.000000  13393.000000   \n",
       "mean      36.775106    168.559807     67.447316     23.240165     78.796842   \n",
       "std       13.625639      8.426583     11.949666      7.256844     10.742033   \n",
       "min       21.000000    125.000000     26.300000      3.000000      0.000000   \n",
       "25%       25.000000    162.400000     58.200000     18.000000     71.000000   \n",
       "50%       32.000000    169.200000     67.400000     22.800000     79.000000   \n",
       "75%       48.000000    174.800000     75.300000     28.000000     86.000000   \n",
       "max       64.000000    193.800000    138.100000     78.400000    156.200000   \n",
       "\n",
       "           systolic     gripForce  sit and bend forward_cm  sit-ups counts  \\\n",
       "count  13393.000000  13393.000000             13393.000000    13393.000000   \n",
       "mean     130.234817     36.963877                15.209268       39.771224   \n",
       "std       14.713954     10.624864                 8.456677       14.276698   \n",
       "min        0.000000      0.000000               -25.000000        0.000000   \n",
       "25%      120.000000     27.500000                10.900000       30.000000   \n",
       "50%      130.000000     37.900000                16.200000       41.000000   \n",
       "75%      141.000000     45.200000                20.700000       50.000000   \n",
       "max      201.000000     70.500000               213.000000       80.000000   \n",
       "\n",
       "       broad jump_cm      gender_F      gender_M  \n",
       "count   13393.000000  13393.000000  13393.000000  \n",
       "mean      190.129627      0.367804      0.632196  \n",
       "std        39.868000      0.482226      0.482226  \n",
       "min         0.000000      0.000000      0.000000  \n",
       "25%       162.000000      0.000000      0.000000  \n",
       "50%       193.000000      0.000000      1.000000  \n",
       "75%       221.000000      1.000000      1.000000  \n",
       "max       303.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Comparison with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.41409932 -0.07652043  1.11987994  1.87635321 -0.99278248  1.10132692\n",
      "   0.61974    -0.04853377 -1.59134486]\n",
      " [-1.18537334 -0.04545084  0.15878133  0.32179436 -0.28878665  0.18766268\n",
      "   0.13837957 -0.0767379  -0.1943455 ]\n",
      " [-1.12144996 -0.01379161 -0.01437194 -0.11733073 -0.10340796 -0.21080821\n",
      "  -0.30513723  0.04083779  0.32180087]\n",
      " [-2.13932052  0.15446421 -1.22976883 -1.79134747  1.36491043 -0.62400042\n",
      "  -0.27894579  0.12101879  1.58349591]]\n",
      "Accuracy: 0.5819335572974991\n",
      "CPU times: user 195 ms, sys: 94.6 ms, total: 290 ms\n",
      "Wall time: 39.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_sk = SKLogisticRegression(solver='liblinear') # all params default\n",
    "lr_sk.fit(X_train,y_train)\n",
    "print(np.hstack((lr_sk.intercept_[:,np.newaxis],lr_sk.coef_)))\n",
    "yhat = lr_sk.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "#precision = precision_score(y_test, yhat, average='weighted')  \n",
    "#recall = recall_score(y_test, yhat, average='weighted')  \n",
    "#f1 = f1_score(y_test, yhat, average='weighted')  \n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "#print(\"Precision:\", precision)\n",
    "#print(\"Recall:\", recall)\n",
    "#print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deployment\n",
    "\n",
    "Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party implementation)? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exceptional Work\n",
    "\n",
    "Implement an optimization technique for logistic regression using mean square error as your objective function (instead of maximum likelihood). Derive the gradient updates for the Hessian and use Newton's method to update the values of \"w\". Then answer, which process do you prefer: maximum likelihood OR minimum mean-squared error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE) Approach \n",
    "\n",
    "In logistic regression, the Mean Squared Error (MSE) approach minimizes the squared difference between predicted probabilities and actual labels.\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "The gradient of the MSE loss with respect to the weights is computed as:\n",
    "\n",
    "$$\n",
    "\\nabla l(\\mathbf{w}) = \\frac{1}{N} \\mathbf{X}^T (\\mathbf{y} - \\hat{\\mathbf{y}})\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{X}$ is the design matrix\n",
    "- $\\mathbf{y}$ is the true labels\n",
    "- $\\hat{\\mathbf{y}}$ is the predicted labels\n",
    "\n",
    "We compute the gradient of the MSE loss function with respect to the model parameters and update the parameters iteratively until convergence.\n",
    "\n",
    "The Hessian matrix is computed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{H} = \\frac{1}{N} \\mathbf{X}^T \\mathbf{X}\n",
    "$$\n",
    "\n",
    "Using Newton's method, we iteratively update the weights as:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{\\text{new}} = \\mathbf{w}_{\\text{old}} - (\\mathbf{H}^{-1} \\nabla l(\\mathbf{w}_{\\text{old}}))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionMSE:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.weights = None  # Initialize weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.w_ = np.zeros((num_features + 1, 1))\n",
    "        X = np.c_[np.ones((num_samples, 1)), X]  # Add intercept\n",
    "        \n",
    "        for _ in range(self.iters):\n",
    "            y_pred = self._sigmoid(X @ self.w_)\n",
    "            y_pred = y_pred.flatten()\n",
    "            gradient = X.T @ (y_pred - y) / num_samples\n",
    "            hessian = X.T @ X / num_samples\n",
    "            gradient = gradient.reshape(-1, 1) # Reshape gradient to ensure it's treated as a column vector\n",
    "            self.w_ -= self.eta * np.linalg.inv(hessian) @ gradient # Update the model parameters using Newton's method\n",
    "        \n",
    "        self.weights = self.w_  # Store weights\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return self._sigmoid(X @ self.w_)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return (probabilities >= 0.5).astype(int)\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        z_clipped = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z_clipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 65.34428434]\n",
      " [  2.73227359]\n",
      " [-24.86548843]\n",
      " [-38.7678778 ]\n",
      " [ 23.9149409 ]\n",
      " [-17.73570103]\n",
      " [-11.76043133]\n",
      " [  3.20034628]\n",
      " [ 37.35061185]]\n",
      "Accuracy: 0.3523702874206794\n",
      "CPU times: user 3.21 s, sys: 123 ms, total: 3.33 s\n",
      "Wall time: 425 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_mse = LogisticRegressionMSE(eta=0.1, iterations=1000)\n",
    "\n",
    "lr_mse.fit(X_train, y_train)\n",
    "y_pred = lr_mse.predict(X_test)\n",
    "print(np.vstack((lr_mse.weights[0], lr_mse.weights[1:])))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionMSEOvR: # One vs. All multiclass with MSE\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.classifiers = {}  # Dictionary to store binary classifiers\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        \n",
    "        for class_label in unique_classes:\n",
    "            y_binary = (y == class_label).astype(int)  # Convert to binary labels\n",
    "            classifier = LogisticRegressionMSE(self.eta, self.iters)\n",
    "            classifier.fit(X, y_binary)\n",
    "            self.classifiers[class_label] = classifier\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        num_samples = X.shape[0]\n",
    "        probabilities = np.zeros((num_samples, len(self.classifiers)))\n",
    "        \n",
    "        for i, (class_label, classifier) in enumerate(self.classifiers.items()):\n",
    "            probabilities[:, i] = classifier.predict_proba(X).flatten()\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return np.argmax(probabilities, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.19701082 -1.18614417 -1.12209991 -2.01123338]\n",
      " [-0.06948775 -0.0454751  -0.01379986  0.14468911]\n",
      " [ 1.01139011  0.15890944 -0.01438236 -1.13946324]\n",
      " [ 1.68106384  0.32210358 -0.11740654 -1.66290641]\n",
      " [-0.883847   -0.28910844 -0.10350916  1.26607836]\n",
      " [ 0.9722856   0.18791939 -0.21102579 -0.57993279]\n",
      " [ 0.5654239   0.13864962 -0.3056917  -0.25859165]\n",
      " [-0.04832219 -0.0768913   0.04091497  0.11430389]\n",
      " [-1.47864458 -0.19487226  0.32259268  1.47253174]]\n",
      "Accuracy: 0.5759611795446062\n",
      "CPU times: user 11.8 s, sys: 408 ms, total: 12.2 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_ovr = LogisticRegressionMSEOvR(eta=0.1, iterations=1000)\n",
    "# Fit the model to your data\n",
    "lr_ovr.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = lr_ovr.predict(X_test)\n",
    "weights_stacked = np.hstack([lr_ovr.classifiers[class_label].weights for class_label in lr_ovr.classifiers])\n",
    "print(weights_stacked)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
