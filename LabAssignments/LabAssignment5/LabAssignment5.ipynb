{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Five: Wide and Deep Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "- Juliana Antonio\n",
    "- Xiaona Hang\n",
    "- Chuanqi Deng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268255 entries, 0 to 268254\n",
      "Data columns (total 24 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Maker         268255 non-null  object \n",
      " 1    Genmodel     268255 non-null  object \n",
      " 2    Genmodel_ID  268255 non-null  object \n",
      " 3   Adv_ID        268255 non-null  object \n",
      " 4   Adv_year      268255 non-null  int64  \n",
      " 5   Adv_month     268255 non-null  int64  \n",
      " 6   Color         246380 non-null  object \n",
      " 7   Reg_year      268248 non-null  float64\n",
      " 8   Bodytype      267301 non-null  object \n",
      " 9   Runned_Miles  267200 non-null  object \n",
      " 10  Engin_size    266191 non-null  object \n",
      " 11  Gearbox       268088 non-null  object \n",
      " 12  Fuel_type     267846 non-null  object \n",
      " 13  Price         267110 non-null  float64\n",
      " 14  Engine_power  236444 non-null  float64\n",
      " 15  Annual_Tax    221580 non-null  object \n",
      " 16  Wheelbase     240257 non-null  float64\n",
      " 17  Height        240454 non-null  float64\n",
      " 18  Width         240175 non-null  float64\n",
      " 19  Length        240454 non-null  float64\n",
      " 20  Average_mpg   226322 non-null  object \n",
      " 21  Top_speed     224653 non-null  object \n",
      " 22  Seat_num      261781 non-null  float64\n",
      " 23  Door_num      263702 non-null  float64\n",
      "dtypes: float64(9), int64(2), object(13)\n",
      "memory usage: 49.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maker</th>\n",
       "      <th>Genmodel</th>\n",
       "      <th>Genmodel_ID</th>\n",
       "      <th>Adv_ID</th>\n",
       "      <th>Adv_year</th>\n",
       "      <th>Adv_month</th>\n",
       "      <th>Color</th>\n",
       "      <th>Reg_year</th>\n",
       "      <th>Bodytype</th>\n",
       "      <th>Runned_Miles</th>\n",
       "      <th>...</th>\n",
       "      <th>Engine_power</th>\n",
       "      <th>Annual_Tax</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average_mpg</th>\n",
       "      <th>Top_speed</th>\n",
       "      <th>Seat_num</th>\n",
       "      <th>Door_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>60000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$2</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>44000</td>\n",
       "      <td>...</td>\n",
       "      <td>450.0</td>\n",
       "      <td>315</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>13.7 mpg</td>\n",
       "      <td>179 mph</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$3</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>55000</td>\n",
       "      <td>...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>315</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>14.7 mpg</td>\n",
       "      <td>155 mph</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$4</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Green</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>14000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>10_1</td>\n",
       "      <td>10_1$$5</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>61652</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Maker  Genmodel  Genmodel_ID   Adv_ID  Adv_year  Adv_month   Color  \\\n",
       "0  Bentley    Arnage         10_1  10_1$$1      2018          4  Silver   \n",
       "1  Bentley    Arnage         10_1  10_1$$2      2018          6    Grey   \n",
       "2  Bentley    Arnage         10_1  10_1$$3      2017         11    Blue   \n",
       "3  Bentley    Arnage         10_1  10_1$$4      2018          4   Green   \n",
       "4  Bentley    Arnage         10_1  10_1$$5      2017         11    Grey   \n",
       "\n",
       "   Reg_year Bodytype Runned_Miles  ... Engine_power Annual_Tax Wheelbase  \\\n",
       "0    2000.0   Saloon        60000  ...          NaN        NaN    3116.0   \n",
       "1    2002.0   Saloon        44000  ...        450.0        315    3116.0   \n",
       "2    2002.0   Saloon        55000  ...        400.0        315    3116.0   \n",
       "3    2003.0   Saloon        14000  ...          NaN        NaN    3116.0   \n",
       "4    2003.0   Saloon        61652  ...          NaN        NaN    3116.0   \n",
       "\n",
       "   Height   Width  Length  Average_mpg  Top_speed  Seat_num  Door_num  \n",
       "0  1515.0  2125.0  5390.0          NaN        NaN       5.0       4.0  \n",
       "1  1515.0  2125.0  5390.0     13.7 mpg    179 mph       5.0       4.0  \n",
       "2  1515.0  2125.0  5390.0     14.7 mpg    155 mph       5.0       4.0  \n",
       "3  1515.0  2125.0  5390.0          NaN        NaN       5.0       4.0  \n",
       "4  1515.0  2125.0  5390.0          NaN        NaN       5.0       4.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_ad_extra = pd.read_csv('data/Ad_table (extra).csv')\n",
    "df_ad_extra.info()\n",
    "\n",
    "df_ad_extra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maker has 88 unique values\n",
      "Genmodel has 896 unique values\n",
      "Color has 22 unique values\n",
      "Bodytype has 18 unique values\n",
      "Gearbox has 3 unique values\n",
      "Fuel_type has 13 unique values\n",
      "=====================================================\n",
      "Numerical columns: Index(['Adv_year', 'Adv_month', 'Reg_year', 'Runned_Miles', 'Engin_size',\n",
      "       'Price', 'Engine_power', 'Wheelbase', 'Height', 'Width', 'Length',\n",
      "       'Average_mpg', 'Top_speed', 'Seat_num', 'Door_num'],\n",
      "      dtype='object')\n",
      "Categorical columns: Index(['Maker', 'Genmodel', 'Color', 'Bodytype', 'Gearbox', 'Fuel_type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data=deepcopy(df_ad_extra)\n",
    "data.columns = data.columns.str.replace(' ', '')\n",
    "# Remove columns that are not needed for the model\n",
    "data.drop(['Genmodel_ID', 'Adv_ID', 'Annual_Tax'], axis=1, inplace=True)\n",
    "\n",
    "# Convert Columns numeric data\n",
    "data['Average_mpg'] = data['Average_mpg'].str.extract(r'(\\d+\\.\\d+)').astype(float)\n",
    "data['Top_speed'] = data['Top_speed'].str.extract(r'(\\d+)').astype(float)\n",
    "data['Engin_size'] = data['Engin_size'].str.extract(r'(\\d+\\.\\d+)').astype(float)\n",
    "data['Runned_Miles'] = pd.to_numeric(data['Runned_Miles'], errors='coerce')\n",
    "\n",
    "\n",
    "# Fill categorical columns with the most frequent value (mode)\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "data[categorical_cols] = data[categorical_cols].fillna(\n",
    "    data[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# Get the unique values in each categorical column\n",
    "for col in categorical_cols:\n",
    "    print(\n",
    "        f'{col} has {len(data[col].unique())} unique values')\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get numerical columns\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "data[numerical_cols] = data[numerical_cols].to_numpy().astype(float)\n",
    "\n",
    "print(\"=====================================================\")\n",
    "print(f'Numerical columns: {numerical_cols}')\n",
    "print(f'Categorical columns: {categorical_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216069 entries, 0 to 216068\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Maker         216069 non-null  object \n",
      " 1   Genmodel      216069 non-null  object \n",
      " 2   Adv_year      216069 non-null  float64\n",
      " 3   Adv_month     216069 non-null  float64\n",
      " 4   Color         216069 non-null  object \n",
      " 5   Reg_year      216069 non-null  float64\n",
      " 6   Bodytype      216069 non-null  object \n",
      " 7   Runned_Miles  216069 non-null  float64\n",
      " 8   Engin_size    216069 non-null  float64\n",
      " 9   Gearbox       216069 non-null  object \n",
      " 10  Fuel_type     216069 non-null  object \n",
      " 11  Price         216069 non-null  float64\n",
      " 12  Engine_power  216069 non-null  float64\n",
      " 13  Wheelbase     216069 non-null  float64\n",
      " 14  Height        216069 non-null  float64\n",
      " 15  Width         216069 non-null  float64\n",
      " 16  Length        216069 non-null  float64\n",
      " 17  Average_mpg   216069 non-null  float64\n",
      " 18  Top_speed     216069 non-null  float64\n",
      " 19  Seat_num      216069 non-null  float64\n",
      " 20  Door_num      216069 non-null  float64\n",
      "dtypes: float64(15), object(6)\n",
      "memory usage: 34.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maker</th>\n",
       "      <th>Genmodel</th>\n",
       "      <th>Adv_year</th>\n",
       "      <th>Adv_month</th>\n",
       "      <th>Color</th>\n",
       "      <th>Reg_year</th>\n",
       "      <th>Bodytype</th>\n",
       "      <th>Runned_Miles</th>\n",
       "      <th>Engin_size</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>...</th>\n",
       "      <th>Price</th>\n",
       "      <th>Engine_power</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average_mpg</th>\n",
       "      <th>Top_speed</th>\n",
       "      <th>Seat_num</th>\n",
       "      <th>Door_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>...</td>\n",
       "      <td>28750.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>...</td>\n",
       "      <td>29999.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>155.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>...</td>\n",
       "      <td>24950.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Green</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>...</td>\n",
       "      <td>29995.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bentley</td>\n",
       "      <td>Arnage</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Silver</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Saloon</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>...</td>\n",
       "      <td>26990.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>3116.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>179.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Maker Genmodel  Adv_year  Adv_month   Color  Reg_year Bodytype  \\\n",
       "0  Bentley   Arnage    2018.0        6.0    Grey    2002.0   Saloon   \n",
       "1  Bentley   Arnage    2017.0       11.0    Blue    2002.0   Saloon   \n",
       "2  Bentley   Arnage    2017.0       12.0    Blue    2002.0   Saloon   \n",
       "3  Bentley   Arnage    2018.0        8.0   Green    2002.0   Saloon   \n",
       "4  Bentley   Arnage    2018.0        6.0  Silver    2002.0   Saloon   \n",
       "\n",
       "   Runned_Miles  Engin_size    Gearbox  ...    Price  Engine_power  Wheelbase  \\\n",
       "0       44000.0         6.8  Automatic  ...  28750.0         450.0     3116.0   \n",
       "1       55000.0         6.8  Automatic  ...  29999.0         400.0     3116.0   \n",
       "2       55000.0         6.8  Automatic  ...  24950.0         450.0     3116.0   \n",
       "3       67000.0         6.8  Automatic  ...  29995.0         450.0     3116.0   \n",
       "4       52000.0         6.8  Automatic  ...  26990.0         450.0     3116.0   \n",
       "\n",
       "   Height   Width  Length  Average_mpg  Top_speed  Seat_num  Door_num  \n",
       "0  1515.0  2125.0  5390.0         13.7      179.0       5.0       4.0  \n",
       "1  1515.0  2125.0  5390.0         14.7      155.0       5.0       4.0  \n",
       "2  1515.0  2125.0  5390.0         13.7      179.0       5.0       4.0  \n",
       "3  1515.0  2125.0  5390.0         13.7      179.0       5.0       4.0  \n",
       "4  1515.0  2125.0  5390.0         13.7      179.0       5.0       4.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center> Data Descriptions </center>\n",
    "    \n",
    "|Feature | Data Type | Description  |\n",
    "|-------|---------------|----------|\n",
    "|Maker:| categorical | Automaker name |\n",
    "|Genmodel:| categorical| Generic Model name|\n",
    "|Adv_year:| continuous| Advertisementâ€™s creation year|\n",
    "|Adv_month:| 0-12 months |Advertisementâ€™s creation month|\n",
    "|color: | categorical| The color of the car|\n",
    "|Reg_year: | continuous | This carâ€™s first registration/selling year|\n",
    "|Body_type: | categorical| This carâ€™s body type|\n",
    "|Runned_miles: | continous | This carâ€™s runned mileage|\n",
    "|Engin_size: | continous | This carâ€™s engine size|\n",
    "|Gearbox: | continous | This carâ€™s gearbox |\n",
    "|Fuel_type: | categorical | This carâ€™s fuel type |\n",
    "|**Price**: | continous | This carâ€™s selling price| \n",
    "|Engine_power: | continous | This car's enging power|\n",
    "|Wheelbase: | continous | Horizontal distance between the centers of the front and rear wheels|\n",
    "|Height: | continous | Height of the car|\n",
    "|Width:  | continous | Width of the car|\n",
    "|Length: | continous | Length of the car|\n",
    "|Avg_mpg: | continous | Average miles per gallon |\n",
    "|Top_speed: | continous | Highest speed car can reach |\n",
    "|Seat_num: | discrete | This carâ€™s seats number|\n",
    "|Door_num: | discrete | This car's doors number|\n",
    "\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Python version: 3.11.5 | packaged by conda-forge | (main, Aug 27 2023, 03:33:12) [Clang 15.0.7 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from sklearn import metrics as mt\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "\n",
    "    # Print the versions of TensorFlow, Keras, and Python\n",
    "    print(f'TensorFlow version: {tf.__version__}')\n",
    "    # print(f'Keras version: {keras.__version__}')\n",
    "    print(f'Python version: {sys.version}')\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f'Error importing libraries: {e}')\n",
    "    print('Make sure you have the necessary packages installed (tensorflow, sklearn, etc.)')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorflow dataset, for ease of use later\n",
    "df_train, df_test = train_test_split(data, test_size=0.2)\n",
    "batch_size = 64\n",
    "\n",
    "def create_dataset_from_dataframe(df_input):\n",
    "    \n",
    "    df = df_input.copy()\n",
    "    labels = df['Price']\n",
    "    \n",
    "    df = {key: value.values[:, np.newaxis] for key, value in df_input.items()}\n",
    "    \n",
    "    # create a tf.data.Dataset object\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    " \n",
    "    # enable batching and prefetching\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "\n",
    "    return ds\n",
    "\n",
    "ds_train = create_dataset_from_dataframe(df_train)\n",
    "ds_test = create_dataset_from_dataframe(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Cross-Product\n",
    "\n",
    "Crossing features such as 'Maker' and 'Bodytype' can uncover relationships between vehicle manufacturers and the body styles of their offerings, providing insights into pricing dynamics influenced by brand reputation and aesthetic preferences. Similarly, crossing 'Gearbox' with 'Fuel_type' can reveal interactions between transmission types and fuel preferences, reflecting performance characteristics and market segmentation. However, caution should be exercised when crossing features with high amount of instances, such as 'Genmodel' with 896 unique instances, as it may introduce computational complexity and increase the risk of overfitting. Therefore, prioritizing cross-product combinations based on their relevance to the domain and balancing computational constraints is essential for effectively capturing interactions while mitigating the potential drawbacks of model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FeatureSpace to make data discrete and normalization\n",
    "\n",
    "# Numerical columns: Index(['Adv_year', 'Adv_month', 'Reg_year', 'Runned_Miles', 'Engin_size',\n",
    "#        'Price', 'Engine_power', 'Wheelbase', 'Height', 'Width', 'Length',\n",
    "#        'Average_mpg', 'Top_speed', 'Seat_num', 'Door_num'],\n",
    "#       dtype='object')\n",
    "# Categorical columns: Index(['Maker', 'Genmodel', 'Color', 'Bodytype', 'Gearbox', 'Fuel_type'], dtype='object')\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import FeatureSpace\n",
    "\n",
    "# lump everything together, and concatenate\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        # Categorical feature encoded as string\n",
    "        \"Maker\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"Genmodel\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"Color\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"Bodytype\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"Gearbox\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \"Fuel_type\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        \n",
    "        # Numerical features to make discrete, make into integer with max val\n",
    "        \"Adv_year\": FeatureSpace.float_discretized(num_bins=10),\n",
    "        \"Adv_month\": FeatureSpace.float_discretized(num_bins=12),\n",
    "        \"Reg_year\": FeatureSpace.float_discretized(num_bins=10),\n",
    "        \n",
    "        # Numerical features to normalize (normalization will be learned)\n",
    "        # learns the mean, variance, and if to invert (3 parameters)\n",
    "        \"Runned_Miles\": FeatureSpace.float_normalized(),\n",
    "        \"Engin_size\": FeatureSpace.float_normalized(),\n",
    "        \"Price\": FeatureSpace.float_normalized(),\n",
    "        \"Engine_power\": FeatureSpace.float_normalized(),\n",
    "        \"Wheelbase\": FeatureSpace.float_normalized(),\n",
    "        \"Height\": FeatureSpace.float_normalized(),\n",
    "        \"Width\": FeatureSpace.float_normalized(),\n",
    "        \"Length\": FeatureSpace.float_normalized(),\n",
    "        \"Average_mpg\": FeatureSpace.float_normalized(),\n",
    "        \"Top_speed\": FeatureSpace.float_normalized(),\n",
    "        \"Seat_num\": FeatureSpace.float_normalized(),\n",
    "        \"Door_num\": FeatureSpace.float_normalized(),\n",
    "    },\n",
    "# Specify feature cross with a custom crossing dim\n",
    "    crosses=[\n",
    "        FeatureSpace.cross(feature_names=('Maker', 'Bodytype'), crossing_dim=88 * 18),\n",
    "        FeatureSpace.cross(feature_names=('Fuel_type', 'Gearbox'), crossing_dim=13 * 3),\n",
    "    ],\n",
    "    output_mode=\"concat\", # can also be a dict, processed internally\n",
    ")\n",
    "\n",
    "\n",
    "# Run on the data\n",
    "# create a version of the dataset that can be iterated without labels\n",
    "train_ds_with_no_labels = ds_train.map(lambda x, _: x)  \n",
    "# the adapt function allows the model to learn one-hot encoding sizes\n",
    "feature_space.adapt(train_ds_with_no_labels) # inititalize the feature map to this data\n",
    "\n",
    "\n",
    "# now define a preprocessing operation that returns the processed features\n",
    "preprocessed_ds_train = ds_train.map(lambda x, y: (feature_space(x), y), \n",
    "                                     num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# run it so that we can use the pre-processed data\n",
    "preprocessed_ds_train = preprocessed_ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Run on the test set\n",
    "preprocessed_ds_test = ds_test.map(lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "preprocessed_ds_test = preprocessed_ds_test.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Metric(s) to use to evaluate algorithmâ€™s performance\n",
    "\n",
    "For evaluating the algorithm's performance in predicting vehicle prices, we will choose Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) as evaluation metrics. MAE provides a straightforward measure of the average absolute deviation between predicted and actual prices, which is valuable for assessing the overall accuracy of price predictions in terms of magnitude. RMSE complements MAE by penalizing larger errors more heavily, making it sensitive to outliers and providing a more comprehensive assessment of prediction accuracy. Since the primary objective is to minimize prediction errors and ensure accurate pricing, both MAE and RMSE are appropriate metrics that align well with the business case for the task of vehicle price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for the categorical columns\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "\n",
    "def setup_embedding_from_categorical(feature_space, col_name):\n",
    "\n",
    "    # which is the same as the number of categories\n",
    "    N = len(feature_space.preprocessors[col_name].get_vocabulary())\n",
    "    \n",
    "    # get the output from the feature space, which is input to embedding\n",
    "    x = feature_space.preprocessors[col_name].output\n",
    "    \n",
    "    # use an embedding to deal with integers from feature space\n",
    "    x = Embedding(input_dim=N, \n",
    "                  output_dim=int(np.sqrt(N)), \n",
    "                  input_length=1, name=col_name+'_embed')(x)\n",
    "    \n",
    "    x = Flatten()(x) # get rid of that extra dimension (for time of embedding)\n",
    "    \n",
    "    return x # return the tensor the embedding layer for use in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to use unprocessed features here, to gain access to each output\n",
    "dict_inputs = feature_space.get_inputs()\n",
    "\n",
    "all_branch_outputs = []\n",
    "\n",
    "# for each feature, setup the embedding\n",
    "for col in categorical_cols:\n",
    "    \n",
    "    # get the output rensor from embedding layer\n",
    "    x = setup_embedding_from_categorical(feature_space, col)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "# for each numerical feature, add it in after embedding\n",
    "for col in numerical_cols:\n",
    "    x = feature_space.preprocessors[col].output\n",
    "    x = tf.cast(x, float) # make sure it is a float\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "# now concatenate the outputs and add a fully connected layer\n",
    "final_branch = Concatenate(name='concat_1')(all_branch_outputs)\n",
    "# final_branch = Dense(units=1,\n",
    "#                      activation='sigmoid', \n",
    "#                      name='combined')(final_branch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Dividing Training and Testing Set\n",
    "\n",
    "We will use shuffle splits to divide the data into training and testing sets for regression, as it ensures random sampling without requiring stratification. This method is appropriate for regression tasks because it provides unbiased estimates of model performance by repeatedly shuffling and splitting the data. It mirrors real-world scenarios where models need to generalize well to unseen data, making it a practical choice for evaluating model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Volvo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d9/62p719dn2gqc7369b_76xrz1n4r_rw/T/ipykernel_37687/550233686.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 )\n\u001b[1;32m   1150\u001b[0m             ):\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    679\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         )\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         raise ValueError(\n\u001b[1;32m   1144\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         )\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 raise ValueError(\n\u001b[1;32m    920\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         if (\n\u001b[1;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Volvo'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize shuffle splits\n",
    "shuffle_split = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a model (e.g., Linear Regression)\n",
    "clf = LinearRegression()\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(shuffle_split.split(data)):\n",
    "    # Split data into training and testing sets\n",
    "    train_data = data.iloc[train_idx]\n",
    "    test_data = data.iloc[test_idx]\n",
    "    \n",
    "    # Separate features and target variable\n",
    "    X_train, y_train = train_data.drop('Price', axis=1), train_data['Price']\n",
    "    X_test, y_test = test_data.drop('Price', axis=1), test_data['Price']\n",
    "    \n",
    "    # Train the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate model performance using mean squared error\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"Fold {fold+1} - Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
